{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect LLM response w.r.t questions from datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log2, prod, mean\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "from json import loads, dumps\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import tqdm\n",
    "import time\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load saved datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset name: wiki_qa_train.csv \n",
      "num of questions: 873 \n",
      "dataset keys: ['question', 'answer', 'prompt', 'text', 'token', 'top_k_token', 'top_k_prob', 'top_logprobs', 'prompt_tokens', 'completion_tokens', 'response']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>prompt</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>top_k_token</th>\n",
       "      <th>top_k_prob</th>\n",
       "      <th>top_logprobs</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>A glacier cave is a cave formed within the ice...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how much is 1 tablespoon of water</td>\n",
       "      <td>This tablespoon has a capacity of about 15 mL....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how much are the harry potter movies worth</td>\n",
       "      <td>The series also originated much tie-in merchan...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how a rocket engine works</td>\n",
       "      <td>A rocket engine, or simply \"rocket\", is a jet ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how are cholera and typhus transmitted and pre...</td>\n",
       "      <td>Transmission occurs primarily by drinking wate...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                      how are glacier caves formed?   \n",
       "1                  how much is 1 tablespoon of water   \n",
       "2         how much are the harry potter movies worth   \n",
       "3                          how a rocket engine works   \n",
       "4  how are cholera and typhus transmitted and pre...   \n",
       "\n",
       "                                              answer prompt text token  \\\n",
       "0  A glacier cave is a cave formed within the ice...                     \n",
       "1  This tablespoon has a capacity of about 15 mL....                     \n",
       "2  The series also originated much tie-in merchan...                     \n",
       "3  A rocket engine, or simply \"rocket\", is a jet ...                     \n",
       "4  Transmission occurs primarily by drinking wate...                     \n",
       "\n",
       "  top_k_token top_k_prob top_logprobs prompt_tokens completion_tokens response  \n",
       "0                                                                               \n",
       "1                                                                               \n",
       "2                                                                               \n",
       "3                                                                               \n",
       "4                                                                               "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset \n",
    "load_path = \"/Users/jiayangsong/Documents/git/LLM_analysis/hallucination_detection/data/\"\n",
    "dataset_name = \"wiki_qa_train.csv\"\n",
    "\n",
    "df = pd.read_csv(load_path+dataset_name)\n",
    "df[[\"prompt\", \"text\", \"token\", \"top_k_token\", \"top_k_prob\", \"top_logprobs\", \"prompt_tokens\", \"completion_tokens\", \"response\"] ] = \"\"\n",
    "\n",
    "print(f\"dataset name: {dataset_name} \\n\" + \n",
    "      f\"num of questions: {len(df)} \\n\" +\n",
    "      f\"dataset keys: {list(df.columns)}\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create text-completion\n",
    "\n",
    "Model endpoint compatibility\n",
    "\n",
    "*   v1/completions\n",
    "    > text-davinci-003, text-davinci-002, text-curie-001, text-babbage-001, text-ada-001, davinci, curie, babbage, ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"text-davinci-003\"     # one model from v1/completions\n",
    "num_question = len(df)  # num of questiosn feed into llm\n",
    "new_df = df.copy()\n",
    "\n",
    "# check validity of question num\n",
    "assert num_question <= len(df), \"Question number can not be greater than the num of samples in datasets'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=10), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return openai.Completion.create(**kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send question to llm and get response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1443/1443 [4:24:17<00:00, 10.99s/it]  \n"
     ]
    }
   ],
   "source": [
    "# feed questiosn to llm and get response\n",
    "\n",
    "for i in tqdm.tqdm(np.arange(0, num_question)):\n",
    "\n",
    "  question = df.iloc[i][\"question\"]\n",
    "  # if i%100 == 0: print(i)\n",
    "  # create the prompt\n",
    "  prompt = \"Answer the following question with reasons: \\n\\n Question:\" + question \n",
    "  # print(prompt)\n",
    "\n",
    "  # send the request to the API and get the response\n",
    "  response = completion_with_backoff(\n",
    "    model = model_name,\n",
    "    prompt = prompt,    \n",
    "    temperature = 0,        # Between 0 and 2, Higher values make the output more random, while lower values will make it more focused and deterministic.\n",
    "    logprobs = 5,           # Include the log probabilities\n",
    "    presence_penalty = 0,   # Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n",
    "    frequency_penalty = 0,  # Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n",
    "    max_tokens = 300,       # The maximum number of tokens to generate in the completion.\n",
    "  )\n",
    "\n",
    "  # format response\n",
    "  new_response = json.loads(str(response))[\"choices\"][0]\n",
    "  top_logprobs = new_response[\"logprobs\"][\"top_logprobs\"] # top-k prob for each token\n",
    "  num_token_response = len(top_logprobs)                  # num of tokens in response\n",
    "  top_k_prob = np.zeros([num_token_response, 5])          # array to hold all top-k prob [num_token, top_k_prob]\n",
    "  top_k_scores = top_k_prob.copy()                        # top-k score for each token\n",
    "  usgae = json.loads(str(response))[\"usage\"]\n",
    "\n",
    "  # tokens in response\n",
    "  top_k_tokens = [list(content.keys()) for content in top_logprobs]\n",
    "  top_k_tokens = np.array(top_k_tokens)\n",
    "\n",
    "  # sort the order of top-k toekns, prob, socre follwing prob with decending order\n",
    "  for index, content in enumerate(top_logprobs):\n",
    "      top_k_prob[index, :] = np.sort(np.exp(np.array(list(top_logprobs[index].values()))))[::-1]\n",
    "      top_k_scores[index, :] = np.sort(np.array(list(top_logprobs[index].values())))[::-1]\n",
    "      new_index = np.argsort(np.exp(np.array(list(top_logprobs[index].values()))))[::-1]\n",
    "      top_k_tokens[index, :] = top_k_tokens[index, new_index]\n",
    "\n",
    "  # add LLM outputs to dataframe\n",
    "  new_df.at[i, 'prompt'] = prompt                 # input prompt\n",
    "  new_df.at[i, 'response'] = response             # original response\n",
    "  new_df.at[i, 'text'] = new_response[\"text\"]     # text answer\n",
    "  new_df.at[i, 'token'] = top_k_tokens[:,0]       # token answer\n",
    "  new_df.at[i, 'top_k_token'] = top_k_tokens      # top-k tokens\n",
    "  new_df.at[i, 'top_k_prob'] = top_k_prob         # top-k prob\n",
    "  new_df.at[i, 'top_logprobs'] = top_logprobs     # top-k token-prob pair\n",
    "  new_df.at[i, 'prompt_tokens'] = usgae[\"prompt_tokens\"]              # num tokens in prompt\n",
    "  new_df.at[i, 'completion_tokens'] = usgae[\"completion_tokens\"]      # num tokens in response\n",
    "\n",
    "  # time.sleep(10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save response df\n",
    "df_to_save = new_df[new_df[\"text\"]!=\"\"]\n",
    "name_to_save = \"eli5_category_train\"\n",
    "save_path = \"/Users/jiayangsong/Documents/git/LLM_analysis/hallucination_detection/response_data/\"\n",
    "\n",
    "# df_to_save.to_csv(save_path + \"reponse_\" + name_to_save + \"_\"+str(num_question)+\".csv\", index=False)\n",
    "\n",
    "\n",
    "# df_to_save.to_pickle(save_path + \"reponse_\" + name_to_save + \"_\" + str(num_question)+\".pkl\")\n",
    "\n",
    "# dumps(loads(df_to_save.to_json(save_path + \"reponse_\" + name_to_save + \"_\"+str(num_question) + \".json\", \n",
    "#                        orient=\"records\")), lines=True)  \n",
    "\n",
    "# df_to_save.to_json(save_path + \"reponse_\" + name_to_save + \"_\"+str(num_question) + \".json\", orient=\"columns\")\n",
    "\n",
    "df_to_save.to_json(save_path + \"reponse_\" + name_to_save + \"_\" + str(num_question) + \".json\", orient=\"columns\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
