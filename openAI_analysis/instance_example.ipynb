{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import shelve\n",
    "sys.path.append(\"../\")\n",
    "import abstract_state\n",
    "import tqdm\n",
    "from itertools import chain\n",
    "from scipy.stats import ks_2samp\n",
    "from GPT3_utils import get_feature, Get_LLM_Response, task_mode_table, num_table\n",
    "from eval_utils import Evaluator\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('punkt')\n",
    "# from code_analysis import mbpp, human_eval\n",
    "# spacy.cli.download('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llmAnalysis/anaconda3/envs/llm-break/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: mbpp \n",
      "Get instance number: 1 \n",
      "Using spacy model: en_core_web_trf \n",
      "Using embedding model: sentence-transformers/all-mpnet-base-v2 \n",
      "Using LLM model: gpt-4o-mini \n",
      "Taks mode: code\n",
      "Iterating index: 0\n",
      "Complete. Results saved to: ../data/experiment/result/new_results/mbpp_1_gpt-4o-mini.pkl \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llmAnalysis/anaconda3/envs/llm-break/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: humaneval \n",
      "Get instance number: 1 \n",
      "Using spacy model: en_core_web_trf \n",
      "Using embedding model: sentence-transformers/all-mpnet-base-v2 \n",
      "Using LLM model: gpt-4o-mini \n",
      "Taks mode: code\n",
      "Iterating index: 0\n",
      "Complete. Results saved to: ../data/experiment/result/new_results/humaneval_1_gpt-4o-mini.pkl \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Datasets: wiki_qa_test_new, eli5_category_test, cnn_dailymail_3_test, wmt14_fr-en_test, mbpp, humaneval\n",
    "GPT model: gpt-4o-mini,  gpt-4o\n",
    "Task type: qa, summarization, translation, code\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "api_key = \"\"\n",
    "model_name = \"gpt-4o-mini\"\n",
    "data_set_name = \"humaneval\"\n",
    "\n",
    "# num_instance = 5\n",
    "spacy_model = \"en_core_web_trf\"\n",
    "sentence_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "print_freq = 10\n",
    "\n",
    "GPT_invoker = Get_LLM_Response(api_key)\n",
    "\n",
    "for data_set_name in [\"wiki_qa_test_new\", \"eli5_category_test\", \"cnn_dailymail_3_test\", \"wmt14_fr-en_test\", \"mbpp\", \"humaneval\"]:\n",
    "# for data_set_name in [\"humaneval\"]:\n",
    "\n",
    "    output_path = \"../data/experiment/result/new_results/\" + data_set_name + \"_\" + str(num_instance) + \"_\" + model_name + \".pkl\"\n",
    "    mode = task_mode_table[data_set_name]\n",
    "    num_instance = num_table[data_set_name]\n",
    "    if mode == \"code\":\n",
    "        dataset_path = data_set_name\n",
    "    else:\n",
    "        dataset_path = \"../data/experiment/\" + data_set_name + \".csv\"\n",
    "\n",
    "    result = GPT_invoker.get_instance(dataset_path, output_path, num_instance, spacy_model, sentence_model, mode, print_freq, model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
